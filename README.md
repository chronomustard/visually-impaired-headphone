# Visually Impaired Headphone Guidance System

This project uses computer vision to assist visually impaired individuals in navigating their environment. It utilizes object detection with YOLO, perspective transformation, and sliding window techniques to determine navigable paths and provides auditory cues (left, right, straight, or no path) via headphones. Additionally, it sends an emergency message through Telegram.

---

## ğŸ”§ Features

* ğŸ¯ Real-time object detection using YOLO (ONNX model)
* ğŸ” Perspective transformation to simulate a top-down view
* ğŸ§  Path detection using histogram and sliding windows
* ğŸ”ˆ Audio feedback to indicate direction (left, straight, right, or no path)
* âš ï¸ Emergency alert system via Telegram
* ğŸ“ Detection zone annotation using `supervision` for visualization

---

## ğŸ“ Project Structure

```
project/
â”‚
â”œâ”€â”€ asset/
â”‚   â”œâ”€â”€ model/
â”‚   â”‚   â””â”€â”€ best.onnx              # Pretrained YOLO model
â”‚   â”œâ”€â”€ video/
â”‚   â”‚   â””â”€â”€ video_1.mp4            # Input video for testing
â”‚   â””â”€â”€ audio/
â”‚       â”œâ”€â”€ left.mp3
â”‚       â”œâ”€â”€ right.mp3
â”‚       â”œâ”€â”€ straight.mp3
â”‚       â””â”€â”€ nopath.mp3
â”‚
â”œâ”€â”€ main.py                        # Main script
â””â”€â”€ README.md                      # This file
```

---

## ğŸš€ Installation & Setup

1. **Clone this repository**:

   ```bash
   git clone https://github.com/yourusername/visually-impaired-headphones.git
   cd visually-impaired-headphones
   ```

2. **Install dependencies**:

   ```bash
   pip install opencv-python numpy matplotlib ultralytics playsound supervision
   ```

3. **Download the ONNX model** and place it in `asset/model/best.onnx`.

4. **Set up Telegram Bot**:

   * Create a bot via [@BotFather](https://t.me/botfather) on Telegram.
   * Get your `TELE_TOKEN` and `CHAT_ID` and insert them into the script:

     ```python
     TELE_TOKEN = "your_bot_token"
     CHAT_ID = "your_chat_id"
     ```

---

## â–¶ï¸ Usage

Run the script:

```bash
python main.py
```

Press `ESC` to exit.

The system will:

* Capture frames from a video source.
* Detect obstacles using a YOLO model.
* Perform perspective transformation.
* Apply color thresholding and detect navigable paths.
* Provide directional guidance through sound.
* Alert via Telegram when help is needed.

---

## ğŸ“· Visualization

* `Original`: Live video with detection overlay.
* `Transformed`: Bird-eye view for path processing.
* `Path Detection`: Thresholded mask of the path.
* `Sliding Windows`: Visualizes the histogram and detected path.

---

## ğŸµ Audio Cues

| Direction     | Audio File     |
| ------------- | -------------- |
| Go Left       | `left.mp3`     |
| Go Right      | `right.mp3`    |
| Go Straight   | `straight.mp3` |
| No Path Found | `nopath.mp3`   |

---

## ğŸ“¡ Telegram Emergency Alert

When help is needed, a message is automatically sent:

```
Help requested!
```

Make sure your Telegram bot is authorized to message your chat.

---

## ğŸ“Œ Notes

* The YOLO model should be trained specifically for relevant obstacles.
* Tune HSV threshold values (`l_h`, `l_s`, `l_v`, `u_h`, `u_s`, `u_v`) for better performance in different environments.
* For real-time deployment, consider switching the video source to a live webcam:

  ```python
  vidcap = cv2.VideoCapture(0)
  ```

---

## ğŸ§  TODOs

* Add hardware integration (e.g., Raspberry Pi with bone conduction headphones)
* Improve real-time processing performance
* Dynamic thresholding for robust performance in varying light conditions

---

## ğŸ“œ License

This project is under the MIT License.
